#!/usr/bin/env python3
"""
AprilTagé¢æ¿æ£€æµ‹è„šæœ¬
åŠŸèƒ½ï¼šæ£€æµ‹AprilTagé¢æ¿ï¼Œå¹¶è®¡ç®—å…¶ç›¸å¯¹äºç›¸æœºã€å¤¹çˆªã€åŸºåº§çš„ä½ç½®(xyz)å’Œå§¿æ€(rpy)
"""
import cv2
import numpy as np
import pyrealsense2 as rs
from dt_apriltags import Detector
import time
import math
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

# å¯¼å…¥ PiperArm å’Œ SDK
from piper_arm import PiperArm
from piper_sdk import C_PiperInterface_V2

class AprilTagPanelDetector:
    def __init__(self):
        """åˆå§‹åŒ–AprilTagæ£€æµ‹å™¨å’ŒRealSenseç›¸æœº"""
        print("=" * 60)
        print("AprilTagé¢æ¿æ£€æµ‹ç³»ç»Ÿ")
        print("=" * 60)
        
        # ğŸ”§ åˆå§‹åŒ– Piper SDK å’Œè¿åŠ¨å­¦
        print("\n[1/4] åˆå§‹åŒ–æœºæ¢°è‡‚...")
        try:
            self.piper = C_PiperInterface_V2()
            self.piper.ConnectPort()
            self.piper_arm = PiperArm()
            
            # ä» piper_arm è·å–æ‰‹çœ¼æ ‡å®šå‚æ•°
            # link6 (å¤¹çˆª) åˆ° camera çš„å˜æ¢
            link6_q_camera = self.piper_arm.link6_q_camera  # [w, x, y, z]
            link6_t_camera = self.piper_arm.link6_t_camera  # [x, y, z]
            
            # å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
            self.link6_R_camera = self.quaternion_to_rotation_matrix(link6_q_camera)
            self.link6_t_camera = np.array(link6_t_camera)
            
            # æ„å»º link6_T_camera å˜æ¢çŸ©é˜µ (4x4)
            self.link6_T_camera = np.eye(4)
            self.link6_T_camera[:3, :3] = self.link6_R_camera
            self.link6_T_camera[:3, 3] = self.link6_t_camera
            
            print("  âœ“ æœºæ¢°è‡‚è¿æ¥æˆåŠŸ")
            print("  âœ“ å·²åŠ è½½æ‰‹çœ¼æ ‡å®šå‚æ•° (link6_T_camera):")
            print(self.link6_T_camera)
        except Exception as e:
            print(f"  âœ— æœºæ¢°è‡‚åˆå§‹åŒ–å¤±è´¥: {e}")
            print("  âš ï¸  å°†ä½¿ç”¨é»˜è®¤æ‰‹çœ¼æ ‡å®šçŸ©é˜µï¼ˆåŠŸèƒ½å—é™ï¼‰")
            self.piper = None
            self.piper_arm = None
            # ä½¿ç”¨é»˜è®¤çŸ©é˜µ
            self.link6_T_camera = np.eye(4)
            self.link6_T_camera[2, 3] = 0.05
        
        # åˆå§‹åŒ–AprilTagæ£€æµ‹å™¨
        # æ”¯æŒçš„æ ‡ç­¾å®¶æ—: 'tag36h11', 'tag25h9', 'tag16h5', 'tagCircle21h7', 'tagStandard41h12'
        self.tag_family = 'tag25h9'  # æ”¹ä¸ºtag36h11ä»¥æé«˜æ£€æµ‹ç‡
        print(f"\n[2/4] åˆå§‹åŒ–AprilTagæ£€æµ‹å™¨ (å®¶æ—: {self.tag_family})...")
        try:
            self.detector = Detector(
                families=self.tag_family,
                nthreads=4,
                quad_decimate=1.0,      # å°æ ‡ç­¾ä½¿ç”¨å…¨åˆ†è¾¨ç‡
                quad_sigma=0.0,
                refine_edges=1,
                decode_sharpening=0.4,  # æé«˜é”åŒ–å¸®åŠ©å°æ ‡ç­¾æ£€æµ‹
                debug=0
            )
            print("  âœ“ AprilTagæ£€æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"  âœ— AprilTagæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # åˆå§‹åŒ–RealSenseç›¸æœº
        print("\n[3/4] åˆå§‹åŒ–RealSenseç›¸æœº...")
        try:
            self.pipeline = rs.pipeline()
            self.config = rs.config()
            
            # é…ç½®æµ
            self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            
            # å¯åŠ¨ç®¡é“
            profile = self.pipeline.start(self.config)
            
            # ä¼˜åŒ–ç›¸æœºè®¾ç½®
            device = profile.get_device()
            color_sensor = device.first_color_sensor()
            
            # è®¾ç½®è‡ªåŠ¨æ›å…‰å’Œç™½å¹³è¡¡
            color_sensor.set_option(rs.option.enable_auto_exposure, 1)
            color_sensor.set_option(rs.option.enable_auto_white_balance, 1)
            
            # å°è¯•å¢åŠ é”åº¦
            try:
                color_sensor.set_option(rs.option.sharpness, 100)
                print("  âœ“ ç›¸æœºé”åº¦å·²ä¼˜åŒ–")
            except:
                pass
            
            # åˆ›å»ºå¯¹é½å™¨ï¼ˆå¯¹é½æ·±åº¦åˆ°å½©è‰²ï¼‰
            self.align = rs.align(rs.stream.color)
            
            # é¢„çƒ­ç›¸æœº
            for _ in range(30):
                self.pipeline.wait_for_frames()
            
            # è·å–ç›¸æœºå†…å‚
            color_stream = profile.get_stream(rs.stream.color)
            self.color_intrin = color_stream.as_video_stream_profile().intrinsics
            
            # æ„å»ºç›¸æœºå†…å‚çŸ©é˜µ
            self.camera_matrix = np.array([
                [self.color_intrin.fx, 0, self.color_intrin.ppx],
                [0, self.color_intrin.fy, self.color_intrin.ppy],
                [0, 0, 1]
            ], dtype=np.float64)
            
            # ç•¸å˜ç³»æ•°
            self.dist_coeffs = np.array(self.color_intrin.coeffs, dtype=np.float64)
            
            print("  âœ“ RealSenseç›¸æœºåˆå§‹åŒ–æˆåŠŸ")
            print(f"    åˆ†è¾¨ç‡: 640x480")
            print(f"    å†…å‚ fx={self.color_intrin.fx:.2f}, fy={self.color_intrin.fy:.2f}")
            print(f"    ä¸»ç‚¹ cx={self.color_intrin.ppx:.2f}, cy={self.color_intrin.ppy:.2f}")
        except Exception as e:
            print(f"  âœ— RealSenseç›¸æœºåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        # AprilTagå°ºå¯¸ï¼ˆç±³ï¼‰
        self.tag_size = 0.025  # ğŸ”§ é»˜è®¤2.5cmï¼Œæ ¹æ®å®é™…æ ‡ç­¾è°ƒæ•´
        
        print("\n" + "=" * 60)
        print("âœ“ åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 60)
        print("\næ“ä½œè¯´æ˜:")
        print("  [q/ESC] - é€€å‡ºç¨‹åº")
        print("  [s]     - æ›´æ”¹AprilTagå°ºå¯¸")
        print("  [ç©ºæ ¼]  - æš‚åœ/ç»§ç»­")
        print(f"\nå½“å‰AprilTagå°ºå¯¸: {self.tag_size*1000:.1f}mm")
        print("=" * 60 + "\n")
    
    def quaternion_to_rotation_matrix(self, q):
        """
        å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        q: [w, x, y, z]
        """
        w, x, y, z = q
        R = np.array([
            [1 - 2*y*y - 2*z*z,     2*x*y - 2*w*z,     2*x*z + 2*w*y],
            [    2*x*y + 2*w*z, 1 - 2*x*x - 2*z*z,     2*y*z - 2*w*x],
            [    2*x*z - 2*w*y,     2*y*z + 2*w*x, 1 - 2*x*x - 2*y*y]
        ])
        return R
    
    def rotation_matrix_to_euler_angles(self, R):
        """
        å°†æ—‹è½¬çŸ©é˜µè½¬æ¢ä¸ºæ¬§æ‹‰è§’ (roll, pitch, yaw) å•ä½ï¼šå¼§åº¦
        ä½¿ç”¨ZYXé¡ºåº (Yaw-Pitch-Roll)
        """
        sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])
        
        singular = sy < 1e-6
        
        if not singular:
            roll = math.atan2(R[2, 1], R[2, 2])
            pitch = math.atan2(-R[2, 0], sy)
            yaw = math.atan2(R[1, 0], R[0, 0])
        else:
            roll = math.atan2(-R[1, 2], R[1, 1])
            pitch = math.atan2(-R[2, 0], sy)
            yaw = 0
        
        return roll, pitch, yaw
    
    def get_current_joints(self):
        """è·å–å½“å‰å…³èŠ‚è§’åº¦ï¼ˆå¼§åº¦ï¼‰"""
        if self.piper is None:
            return None
        
        try:
            msg = self.piper.GetArmJointMsgs()
            PI = math.pi
            joints = [
                msg.joint_state.joint_1 * 1e-3 * PI / 180.0,
                msg.joint_state.joint_2 * 1e-3 * PI / 180.0,
                msg.joint_state.joint_3 * 1e-3 * PI / 180.0,
                msg.joint_state.joint_4 * 1e-3 * PI / 180.0,
                msg.joint_state.joint_5 * 1e-3 * PI / 180.0,
                msg.joint_state.joint_6 * 1e-3 * PI / 180.0,
            ]
            return joints
        except Exception as e:
            print(f"âš ï¸  è¯»å–å…³èŠ‚è§’åº¦å¤±è´¥: {e}")
            return None
    
    def transform_camera_to_gripper(self, camera_T_tag):
        """
        å°†AprilTagä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°å¤¹çˆªåæ ‡ç³»
        
        Args:
            camera_T_tag: 4x4å˜æ¢çŸ©é˜µï¼ŒAprilTagç›¸å¯¹äºç›¸æœº
            
        Returns:
            gripper_T_tag: 4x4å˜æ¢çŸ©é˜µï¼ŒAprilTagç›¸å¯¹äºå¤¹çˆª
        """
        # link6_T_tag = link6_T_camera @ camera_T_tag
        gripper_T_tag = self.link6_T_camera @ camera_T_tag
        return gripper_T_tag
    
    def transform_camera_to_base(self, camera_T_tag, current_joints):
        """
        å°†AprilTagä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°åŸºåº§åæ ‡ç³»
        
        Args:
            camera_T_tag: 4x4å˜æ¢çŸ©é˜µï¼ŒAprilTagç›¸å¯¹äºç›¸æœº
            current_joints: å½“å‰å…³èŠ‚è§’åº¦åˆ—è¡¨ï¼ˆå¼§åº¦ï¼‰
            
        Returns:
            base_T_tag: 4x4å˜æ¢çŸ©é˜µï¼ŒAprilTagç›¸å¯¹äºåŸºåº§
        """
        if self.piper_arm is None or current_joints is None:
            return None
        
        try:
            # è®¡ç®—æ­£å‘è¿åŠ¨å­¦ï¼šbase_T_link6
            base_T_link6 = self.piper_arm.forward_kinematics(current_joints)
            
            # base_T_tag = base_T_link6 @ link6_T_camera @ camera_T_tag
            base_T_tag = base_T_link6 @ self.link6_T_camera @ camera_T_tag
            
            return base_T_tag
        except Exception as e:
            print(f"âš ï¸  åæ ‡è½¬æ¢å¤±è´¥: {e}")
            return None
    
    def detect_apriltags(self, gray_image):
        """æ£€æµ‹AprilTagæ ‡ç­¾ï¼ˆå¸¦å›¾åƒå¢å¼ºï¼‰"""
        # å›¾åƒé¢„å¤„ç†ä»¥æé«˜å°æ ‡ç­¾æ£€æµ‹
        # 1. è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼ˆCLAHEï¼‰- æé«˜å¯¹æ¯”åº¦
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray_image)
        
        # 2. è½»å¾®é”åŒ–
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1],
                          [-1,-1,-1]])
        enhanced = cv2.filter2D(enhanced, -1, kernel)
        
        # ä½¿ç”¨dt-apriltagsåº“è¿›è¡Œæ£€æµ‹
        detections = self.detector.detect(
            enhanced,
            estimate_tag_pose=True,
            camera_params=[
                self.color_intrin.fx,
                self.color_intrin.fy,
                self.color_intrin.ppx,
                self.color_intrin.ppy
            ],
            tag_size=self.tag_size
        )
        return detections
    
    def draw_detection(self, image, detection):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
        # ç»˜åˆ¶è¾¹æ¡†
        corners = detection.corners.astype(int)
        for i in range(4):
            pt1 = tuple(corners[i])
            pt2 = tuple(corners[(i + 1) % 4])
            cv2.line(image, pt1, pt2, (0, 255, 0), 2)
        
        # ç»˜åˆ¶ä¸­å¿ƒç‚¹
        center = detection.center.astype(int)
        cv2.circle(image, tuple(center), 5, (0, 0, 255), -1)
        
        # ç»˜åˆ¶ID
        cv2.putText(image, f"ID: {detection.tag_id}", 
                    (center[0] - 20, center[1] - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        return image
    
    def draw_axis(self, image, rvec, tvec):
        """ç»˜åˆ¶3Dåæ ‡è½´"""
        axis_length = self.tag_size
        axis = np.float32([
            [axis_length, 0, 0],
            [0, axis_length, 0],
            [0, 0, axis_length],
            [0, 0, 0]
        ]).reshape(-1, 3)
        
        # æŠ•å½±åˆ°å›¾åƒå¹³é¢
        imgpts, _ = cv2.projectPoints(axis, rvec, tvec, self.camera_matrix, self.dist_coeffs)
        imgpts = imgpts.astype(int)
        
        origin = tuple(imgpts[3].ravel())
        # Xè½´ - çº¢è‰²
        image = cv2.line(image, origin, tuple(imgpts[0].ravel()), (0, 0, 255), 3)
        # Yè½´ - ç»¿è‰²
        image = cv2.line(image, origin, tuple(imgpts[1].ravel()), (0, 255, 0), 3)
        # Zè½´ - è“è‰²
        image = cv2.line(image, origin, tuple(imgpts[2].ravel()), (255, 0, 0), 3)
        
        return image
    
    def display_pose_info(self, image, detections, current_joints=None):
        """åœ¨å›¾åƒä¸Šæ˜¾ç¤ºä½å§¿ä¿¡æ¯ï¼ˆç›¸æœºã€å¤¹çˆªã€åŸºåº§ä¸‰ä¸ªåæ ‡ç³»ï¼‰"""
        y_offset = 30
        
        # æ ‡é¢˜
        cv2.putText(image, "AprilTag Pose: Camera/Gripper/Base", (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        y_offset += 28
        
        # æ ‡ç­¾æ•°é‡
        cv2.putText(image, f"Tags: {len(detections)}", (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        y_offset += 22
        
        # æ˜¾ç¤ºæ¯ä¸ªæ ‡ç­¾çš„ä½å§¿
        for i, det in enumerate(detections):
            if det.pose_t is None or det.pose_R is None:
                continue
            
            # ========== ç›¸æœºåæ ‡ç³»ä¸‹çš„ä½å§¿ ==========
            x_cam, y_cam, z_cam = det.pose_t.flatten()
            roll_cam, pitch_cam, yaw_cam = self.rotation_matrix_to_euler_angles(det.pose_R)
            roll_cam_deg = math.degrees(roll_cam)
            pitch_cam_deg = math.degrees(pitch_cam)
            yaw_cam_deg = math.degrees(yaw_cam)
            
            # ========== å¤¹çˆªåæ ‡ç³»ä¸‹çš„ä½å§¿ ==========
            # æ„å»ºç›¸æœºåæ ‡ç³»ä¸‹çš„4x4å˜æ¢çŸ©é˜µ
            camera_T_tag = np.eye(4)
            camera_T_tag[:3, :3] = det.pose_R
            camera_T_tag[:3, 3] = det.pose_t.flatten()
            
            # è½¬æ¢åˆ°å¤¹çˆªåæ ‡ç³»
            gripper_T_tag = self.transform_camera_to_gripper(camera_T_tag)
            
            # æå–å¤¹çˆªåæ ‡ç³»ä¸‹çš„ä½ç½®å’Œå§¿æ€
            x_grip, y_grip, z_grip = gripper_T_tag[:3, 3]
            R_grip = gripper_T_tag[:3, :3]
            roll_grip, pitch_grip, yaw_grip = self.rotation_matrix_to_euler_angles(R_grip)
            roll_grip_deg = math.degrees(roll_grip)
            pitch_grip_deg = math.degrees(pitch_grip)
            yaw_grip_deg = math.degrees(yaw_grip)
            
            # è½¬æ¢åˆ°åŸºåº§åæ ‡ç³»
            base_T_tag = self.transform_camera_to_base(camera_T_tag, current_joints)
            if base_T_tag is not None:
                x_base, y_base, z_base = base_T_tag[:3, 3]
                R_base = base_T_tag[:3, :3]
                roll_base, pitch_base, yaw_base = self.rotation_matrix_to_euler_angles(R_base)
                roll_base_deg = math.degrees(roll_base)
                pitch_base_deg = math.degrees(pitch_base)
                yaw_base_deg = math.degrees(yaw_base)
            else:
                x_base = y_base = z_base = 0
                roll_base_deg = pitch_base_deg = yaw_base_deg = 0
            
            # ========== æ˜¾ç¤ºä¿¡æ¯ ==========
            cv2.putText(image, f"--- Tag ID {det.tag_id} ---", (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 255), 1)
            y_offset += 18
            
            # ç›¸æœºåæ ‡ç³»
            cv2.putText(image, f"[Camera]", (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 200, 255), 1)
            y_offset += 15
            
            cv2.putText(image, f"X:{x_cam:+.3f} Y:{y_cam:+.3f} Z:{z_cam:+.3f}m", (12, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)
            y_offset += 13
            
            cv2.putText(image, f"R:{roll_cam_deg:+.1f} P:{pitch_cam_deg:+.1f} Y:{yaw_cam_deg:+.1f}deg", (12, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)
            y_offset += 16
            
            # å¤¹çˆªåæ ‡ç³»
            cv2.putText(image, f"[Gripper]", (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 255, 100), 1)
            y_offset += 15
            
            cv2.putText(image, f"X:{x_grip:+.3f} Y:{y_grip:+.3f} Z:{z_grip:+.3f}m", (12, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.35, (200, 255, 200), 1)
            y_offset += 13
            
            cv2.putText(image, f"R:{roll_grip_deg:+.1f} P:{pitch_grip_deg:+.1f} Y:{yaw_grip_deg:+.1f}deg", (12, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.35, (200, 255, 200), 1)
            y_offset += 16
            
            # åŸºåº§åæ ‡ç³»
            if base_T_tag is not None:
                cv2.putText(image, f"[Base]", (10, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 150, 100), 1)
                y_offset += 15
                
                cv2.putText(image, f"X:{x_base:+.3f} Y:{y_base:+.3f} Z:{z_base:+.3f}m", (12, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 200, 150), 1)
                y_offset += 13
                
                cv2.putText(image, f"R:{roll_base_deg:+.1f} P:{pitch_base_deg:+.1f} Y:{yaw_base_deg:+.1f}deg", (12, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 200, 150), 1)
                y_offset += 18
            else:
                cv2.putText(image, f"[Base] N/A", (10, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 100, 100), 1)
                y_offset += 18
        
        return image
    
    def run(self):
        """ä¸»å¾ªç¯"""
        is_paused = False
        paused_frame = None
        
        try:
            while True:
                # è·å–å¸§
                if not is_paused:
                    frames = self.pipeline.wait_for_frames()
                    aligned_frames = self.align.process(frames)
                    
                    color_frame = aligned_frames.get_color_frame()
                    depth_frame = aligned_frames.get_depth_frame()
                    
                    if not color_frame or not depth_frame:
                        continue
                    
                    # è½¬æ¢ä¸ºnumpyæ•°ç»„
                    color_image = np.asanyarray(color_frame.get_data())
                    paused_frame = color_image.copy()
                else:
                    color_image = paused_frame.copy()
                
                # è½¬æ¢ä¸ºç°åº¦å›¾
                gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)
                
                # æ£€æµ‹AprilTag
                start_time = time.time()
                detections = self.detect_apriltags(gray)
                detect_time = (time.time() - start_time) * 1000
                
                # è·å–å½“å‰å…³èŠ‚è§’åº¦ï¼ˆç”¨äºåŸºåº§åæ ‡ç³»è½¬æ¢ï¼‰
                current_joints = self.get_current_joints()
                
                # å¯è§†åŒ–
                vis_image = color_image.copy()
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                for det in detections:
                    vis_image = self.draw_detection(vis_image, det)
                    
                    # ç»˜åˆ¶åæ ‡è½´
                    if det.pose_t is not None and det.pose_R is not None:
                        # è½¬æ¢ä¸ºOpenCVæ ¼å¼
                        rvec, _ = cv2.Rodrigues(det.pose_R)
                        tvec = det.pose_t
                        vis_image = self.draw_axis(vis_image, rvec, tvec)
                
                # æ˜¾ç¤ºä½å§¿ä¿¡æ¯ï¼ˆåŒ…å«å½“å‰å…³èŠ‚è§’åº¦ï¼‰
                vis_image = self.display_pose_info(vis_image, detections, current_joints)
                
                # æ˜¾ç¤ºæ£€æµ‹æ—¶é—´
                cv2.putText(vis_image, f"Detection: {detect_time:.1f}ms", 
                            (10, vis_image.shape[0] - 40),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # æ˜¾ç¤ºæ ‡ç­¾å°ºå¯¸
                cv2.putText(vis_image, f"Tag size: {self.tag_size*1000:.1f}mm", 
                            (10, vis_image.shape[0] - 20),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                # æ˜¾ç¤ºæš‚åœçŠ¶æ€
                if is_paused:
                    cv2.putText(vis_image, "PAUSED", (vis_image.shape[1] - 120, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow('AprilTag Panel Detection', vis_image)
                
                # åœ¨æ§åˆ¶å°è¾“å‡ºä½å§¿ä¿¡æ¯
                if detections and not is_paused:
                    # è·å–å½“å‰å…³èŠ‚è§’åº¦
                    current_joints = self.get_current_joints()
                    
                    print("\n" + "=" * 80)
                    print(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªAprilTagæ ‡ç­¾")
                    print("=" * 80)
                    for det in detections:
                        if det.pose_t is None or det.pose_R is None:
                            continue
                        
                        # ç›¸æœºåæ ‡ç³»
                        x_cam, y_cam, z_cam = det.pose_t.flatten()
                        roll_cam, pitch_cam, yaw_cam = self.rotation_matrix_to_euler_angles(det.pose_R)
                        
                        # å¤¹çˆªåæ ‡ç³»
                        camera_T_tag = np.eye(4)
                        camera_T_tag[:3, :3] = det.pose_R
                        camera_T_tag[:3, 3] = det.pose_t.flatten()
                        gripper_T_tag = self.transform_camera_to_gripper(camera_T_tag)
                        x_grip, y_grip, z_grip = gripper_T_tag[:3, 3]
                        R_grip = gripper_T_tag[:3, :3]
                        roll_grip, pitch_grip, yaw_grip = self.rotation_matrix_to_euler_angles(R_grip)
                        
                        # åŸºåº§åæ ‡ç³»
                        base_T_tag = self.transform_camera_to_base(camera_T_tag, current_joints)
                        
                        print(f"\n[Tag ID: {det.tag_id}]")
                        print(f"  ğŸ“· ç›¸æœºåæ ‡ç³» (Camera Frame):")
                        print(f"     ä½ç½® (ç±³): X={x_cam:+.4f}, Y={y_cam:+.4f}, Z={z_cam:+.4f}")
                        print(f"     å§¿æ€ (åº¦): Roll={math.degrees(roll_cam):+.2f}, Pitch={math.degrees(pitch_cam):+.2f}, Yaw={math.degrees(yaw_cam):+.2f}")
                        
                        print(f"  ğŸ¤– å¤¹çˆªåæ ‡ç³» (Gripper Frame):")
                        print(f"     ä½ç½® (ç±³): X={x_grip:+.4f}, Y={y_grip:+.4f}, Z={z_grip:+.4f}")
                        print(f"     å§¿æ€ (åº¦): Roll={math.degrees(roll_grip):+.2f}, Pitch={math.degrees(pitch_grip):+.2f}, Yaw={math.degrees(yaw_grip):+.2f}")
                        
                        if base_T_tag is not None:
                            x_base, y_base, z_base = base_T_tag[:3, 3]
                            R_base = base_T_tag[:3, :3]
                            roll_base, pitch_base, yaw_base = self.rotation_matrix_to_euler_angles(R_base)
                            print(f"  ğŸ  åŸºåº§åæ ‡ç³» (Base Frame):")
                            print(f"     ä½ç½® (ç±³): X={x_base:+.4f}, Y={y_base:+.4f}, Z={z_base:+.4f}")
                            print(f"     å§¿æ€ (åº¦): Roll={math.degrees(roll_base):+.2f}, Pitch={math.degrees(pitch_base):+.2f}, Yaw={math.degrees(yaw_base):+.2f}")
                        else:
                            print(f"  ğŸ  åŸºåº§åæ ‡ç³»: ä¸å¯ç”¨ (éœ€è¦æœºæ¢°è‡‚è¿æ¥)")
                        
                        print(f"  ç½®ä¿¡åº¦: {det.decision_margin:.2f}, æ±‰æ˜è·ç¦»: {det.hamming}")
                    print("=" * 80)
                
                # é”®ç›˜æ§åˆ¶
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # qæˆ–ESCé€€å‡º
                    print("\né€€å‡ºç¨‹åº...")
                    break
                elif key == ord(' '):  # ç©ºæ ¼é”®æš‚åœ/ç»§ç»­
                    is_paused = not is_paused
                    if is_paused:
                        print("\nâ¸  å·²æš‚åœ")
                    else:
                        print("\nâ–¶  ç»§ç»­")
                elif key == ord('s'):  # æ›´æ”¹æ ‡ç­¾å°ºå¯¸
                    print(f"\nå½“å‰AprilTagå°ºå¯¸: {self.tag_size*1000:.1f}mm")
                    try:
                        new_size = float(input("è¯·è¾“å…¥æ–°çš„æ ‡ç­¾å°ºå¯¸(mm): ")) / 1000.0
                        if new_size > 0:
                            self.tag_size = new_size
                            print(f"âœ“ æ ‡ç­¾å°ºå¯¸å·²æ›´æ–°ä¸º: {self.tag_size*1000:.1f}mm")
                        else:
                            print("âœ— æ— æ•ˆå°ºå¯¸")
                    except:
                        print("âœ— è¾“å…¥æ— æ•ˆ")
        
        except KeyboardInterrupt:
            print("\næ£€æµ‹åˆ°Ctrl+Cï¼Œé€€å‡ºç¨‹åº...")
        
        finally:
            # æ¸…ç†èµ„æº
            self.pipeline.stop()
            cv2.destroyAllWindows()
            if self.piper is not None:
                try:
                    self.piper.DisconnectPort()
                except:
                    pass
            print("\nâœ“ èµ„æºå·²æ¸…ç†")

def main():
    """ä¸»å‡½æ•°"""
    try:
        detector = AprilTagPanelDetector()
        detector.run()
    except Exception as e:
        print(f"\nâœ— é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
