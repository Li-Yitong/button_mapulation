#!/usr/bin/env python3
"""
å®æ—¶è¿½è¸ªé¢æ¿æ³•å‘é‡ (MoveIt2ç‰ˆæœ¬)
åŠŸèƒ½ï¼šè®©å¤¹çˆªçš„Zè½´å§‹ç»ˆå‚ç›´å¯¹é½äºæ£€æµ‹åˆ°çš„é¢æ¿å¹³é¢
"""
import sys
import time
import numpy as np
import pyrealsense2 as rs
import cv2
from typing import Optional, Tuple
import rclpy
from rclpy.node import Node
from rclpy.action import ActionClient
from moveit_msgs.action import MoveGroup as MoveGroupAction
from moveit_msgs.msg import MotionPlanRequest, Constraints, JointConstraint
from sensor_msgs.msg import JointState
import time as time_module

from piper_sdk import C_PiperInterface_V2
from piper_arm import PiperArm
from utils.utils_plane import fit_plane_ransac
from utils.utils_math import quaternion_to_rotation_matrix

PI = np.pi

# ========================================
# å…¨å±€å˜é‡
# ========================================
piper = None
piper_arm = None
pipeline = None
ros_node = None
action_client = None
joint_state_publisher = None
ros2_executor = None
ros2_spin_thread = None


def initialize_hardware():
    """åˆå§‹åŒ–æœºæ¢°è‡‚å’Œç›¸æœº"""
    global piper, piper_arm, pipeline
    
    print("="*70)
    print("åˆå§‹åŒ–ç¡¬ä»¶")
    print("="*70)
    
    # 1. åˆå§‹åŒ–æœºæ¢°è‡‚
    print("\n[1/3] åˆå§‹åŒ–æœºæ¢°è‡‚...")
    try:
        piper = C_PiperInterface_V2("can0")
        piper.ConnectPort()
        
        # ç®€å•ä½¿èƒ½ï¼ˆä¸é€€å‡ºï¼‰
        print("  æ­£åœ¨ä½¿èƒ½...")
        for _ in range(10):
            piper.EnableArm(7)
            time.sleep(0.5)
            status = piper.GetArmLowSpdInfoMsgs()
            enabled = (status.motor_1.foc_status.driver_enable_status and
                      status.motor_2.foc_status.driver_enable_status and
                      status.motor_3.foc_status.driver_enable_status and
                      status.motor_4.foc_status.driver_enable_status and
                      status.motor_5.foc_status.driver_enable_status and
                      status.motor_6.foc_status.driver_enable_status)
            if enabled:
                print("  âœ“ æœºæ¢°è‡‚ä½¿èƒ½æˆåŠŸ")
                break
        else:
            print("  âš ï¸  éƒ¨åˆ†å…³èŠ‚å¯èƒ½æœªä½¿èƒ½ï¼Œä½†ç»§ç»­è¿è¡Œ...")
        
        # è®¾ç½®è¿åŠ¨æ¨¡å¼ï¼ˆé«˜é€Ÿè¿½è¸ªæ¨¡å¼ï¼‰
        piper.MotionCtrl_2(
            ctrl_mode=0x01,      # CANæ§åˆ¶
            move_mode=0x00,      # MOVEJ
            move_spd_rate_ctrl=50,  # é€Ÿåº¦50%ï¼ˆä»30%æé«˜ï¼‰
            is_mit_mode=0x00
        )
        
    except Exception as e:
        print(f"  âœ— æœºæ¢°è‡‚åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # 2. åˆå§‹åŒ–è¿åŠ¨å­¦
    print("\n[2/3] åˆå§‹åŒ–è¿åŠ¨å­¦...")
    try:
        piper_arm = PiperArm()
        print("  âœ“ PiperArm åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— PiperArm åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # 3. åˆå§‹åŒ–RealSense
    print("\n[3/3] åˆå§‹åŒ–RealSenseç›¸æœº...")
    try:
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        pipeline.start(config)
        
        # é¢„çƒ­ç›¸æœº
        for _ in range(10):
            pipeline.wait_for_frames()
        
        print("  âœ“ RealSense åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— RealSense åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    print("\nâœ“âœ“âœ“ æ‰€æœ‰ç¡¬ä»¶åˆå§‹åŒ–å®Œæˆ âœ“âœ“âœ“\n")
    return True


def initialize_ros2() -> bool:
    """
    åˆå§‹åŒ–ROS2èŠ‚ç‚¹å’ŒMoveIt2 action client
    
    è¿”å›:
        True: æˆåŠŸ, False: å¤±è´¥
    """
    global ros_node, action_client, joint_state_publisher, ros2_executor, ros2_spin_thread
    
    try:
        import rclpy.executors
        import threading
        
        # åˆå§‹åŒ–ROS2
        if not rclpy.ok():
            rclpy.init()
        
        # åˆ›å»ºèŠ‚ç‚¹
        node_name = f'track_panel_normal_{int(time_module.time() * 1000)}'
        ros_node = Node(node_name)
        print(f"  âœ“ åˆ›å»ºROS2èŠ‚ç‚¹: {node_name}")
        
        # åˆ›å»ºMoveIt2 action client
        action_client = ActionClient(ros_node, MoveGroupAction, '/move_action')
        print("  âœ“ Action Clientå·²åˆ›å»º")
        
        # åˆ›å»ºjoint_stateså‘å¸ƒå™¨
        joint_state_publisher = ros_node.create_publisher(JointState, '/joint_states', 10)
        print("  âœ“ joint_stateså‘å¸ƒå™¨å·²å¯åŠ¨")
        
        # å¯åŠ¨åå°spinçº¿ç¨‹
        ros2_executor = rclpy.executors.SingleThreadedExecutor()
        ros2_executor.add_node(ros_node)
        ros2_spin_thread = threading.Thread(target=ros2_executor.spin, daemon=True)
        ros2_spin_thread.start()
        print("  âœ“ ROS2 spinçº¿ç¨‹å·²å¯åŠ¨")
        
        # ç­‰å¾…action server
        print("  â³ ç­‰å¾…MoveIt2 action server...")
        timeout = 10.0
        start_time = time_module.time()
        
        while not action_client.server_is_ready():
            time_module.sleep(0.2)
            elapsed = time_module.time() - start_time
            if elapsed > timeout:
                print("  âš ï¸  MoveIt2 action serveræœªå¯åŠ¨ï¼Œè¯·å…ˆè¿è¡Œstart_moveit2.sh")
                return False
        
        # ROS2 Foxyéœ€è¦é¢å¤–ç­‰å¾…æ—¶é—´
        print("  âœ“ Action serverå·²å°±ç»ªï¼Œç­‰å¾…æœåŠ¡å®Œå…¨å¯åŠ¨...")
        time_module.sleep(2.0)
        
        print("âœ… MoveIt2è¿æ¥æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"  âš ï¸  ROS2åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def get_current_joints() -> np.ndarray:
    """è¯»å–å½“å‰å…³èŠ‚è§’åº¦ï¼ˆå¼§åº¦ï¼‰"""
    msg = piper.GetArmJointMsgs()
    return np.array([
        msg.joint_state.joint_1 * 1e-3 * PI / 180.0,
        msg.joint_state.joint_2 * 1e-3 * PI / 180.0,
        msg.joint_state.joint_3 * 1e-3 * PI / 180.0,
        msg.joint_state.joint_4 * 1e-3 * PI / 180.0,
        msg.joint_state.joint_5 * 1e-3 * PI / 180.0,
        msg.joint_state.joint_6 * 1e-3 * PI / 180.0
    ])


def detect_panel_normal(depth_frame, color_frame, 
                       center_x: int = 320, center_y: int = 240,
                       roi_size: int = 60) -> Optional[Tuple[np.ndarray, np.ndarray]]:
    """
    æ£€æµ‹é¢æ¿æ³•å‘é‡å’Œä¸­å¿ƒç‚¹ä½ç½®ï¼ˆç›¸æœºåæ ‡ç³»ï¼‰
    
    å‚æ•°:
        depth_frame: æ·±åº¦å¸§
        color_frame: å½©è‰²å¸§
        center_x, center_y: æ£€æµ‹ä¸­å¿ƒç‚¹ï¼ˆå±å¹•åƒç´ åæ ‡ï¼‰
        roi_size: ROIåŠå¾„ï¼ˆåƒç´ ï¼‰
    
    è¿”å›:
        (æ³•å‘é‡, ä¸­å¿ƒç‚¹3Dä½ç½®) æˆ– None
    """
    # è·å–æ·±åº¦å†…å‚
    depth_intrin = depth_frame.profile.as_video_stream_profile().intrinsics
    
    # å®šä¹‰ROI
    x_min = max(0, center_x - roi_size)
    x_max = min(depth_intrin.width, center_x + roi_size)
    y_min = max(0, center_y - roi_size)
    y_max = min(depth_intrin.height, center_y + roi_size)
    
    # æå–ROIå†…çš„3Dç‚¹äº‘ï¼ˆç¨€ç–é‡‡æ ·åŠ é€Ÿï¼‰
    points_3d = []
    for y in range(y_min, y_max, 4):  # æ¯éš”4åƒç´ é‡‡æ ·ï¼Œæé«˜é€Ÿåº¦
        for x in range(x_min, x_max, 4):
            depth_value = depth_frame.get_distance(x, y)
            if 0.1 < depth_value < 2.0:  # æœ‰æ•ˆæ·±åº¦èŒƒå›´
                point_3d = rs.rs2_deproject_pixel_to_point(depth_intrin, [x, y], depth_value)
                points_3d.append(point_3d)
    
    if len(points_3d) < 30:  # é™ä½æœ€å°ç‚¹æ•°è¦æ±‚
        return None
    
    points_3d = np.array(points_3d)
    
    # RANSACæ‹Ÿåˆå¹³é¢ï¼ˆå‡å°‘è¿­ä»£æ¬¡æ•°åŠ é€Ÿï¼‰
    normal_camera, d, inliers = fit_plane_ransac(
        points_3d,
        distance_threshold=0.010,  # æ”¾å®½åˆ°10mmå®¹å·®
        max_iterations=200  # ä»500é™åˆ°200æ¬¡è¿­ä»£
    )
    
    if normal_camera is None:
        return None
    
    # ç¡®ä¿æ³•å‘é‡æŒ‡å‘ç›¸æœºï¼ˆZåˆ†é‡ä¸ºè´Ÿï¼‰
    if normal_camera[2] > 0:
        normal_camera = -normal_camera
    
    # è®¡ç®—ROIä¸­å¿ƒçš„3Dç‚¹ä½ç½®
    depth_intrin = depth_frame.profile.as_video_stream_profile().intrinsics
    center_depth = depth_frame.get_distance(center_x, center_y)
    
    if center_depth < 0.1 or center_depth > 2.0:
        return None
    
    center_point_3d = np.array(rs.rs2_deproject_pixel_to_point(
        depth_intrin, [center_x, center_y], center_depth
    ))
    
    return normal_camera, center_point_3d


def transform_normal_to_base(normal_camera: np.ndarray, current_joints: np.ndarray) -> np.ndarray:
    """
    å°†æ³•å‘é‡ä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°åŸºåº§æ ‡ç³»
    
    å‚æ•°:
        normal_camera: æ³•å‘é‡ï¼ˆç›¸æœºç³»ï¼‰
        current_joints: å½“å‰å…³èŠ‚è§’åº¦
    
    è¿”å›:
        æ³•å‘é‡ï¼ˆåŸºåº§ç³»ï¼‰
    """
    # åŸºåº§åˆ°link6çš„å˜æ¢
    base_T_link6 = piper_arm.forward_kinematics(current_joints)
    
    # link6åˆ°ç›¸æœºçš„å˜æ¢
    link6_T_cam = np.eye(4)
    link6_T_cam[:3, :3] = quaternion_to_rotation_matrix(piper_arm.link6_q_camera)
    link6_T_cam[:3, 3] = piper_arm.link6_t_camera
    
    # ç»„åˆå˜æ¢
    base_T_cam = base_T_link6 @ link6_T_cam
    
    # åªè½¬æ¢æ—‹è½¬éƒ¨åˆ†ï¼ˆæ³•å‘é‡æ˜¯æ–¹å‘ï¼‰
    R_base_cam = base_T_cam[:3, :3]
    normal_base = R_base_cam @ normal_camera
    normal_base = normal_base / np.linalg.norm(normal_base)
    
    return normal_base


def compute_aligned_pose_with_distance(current_joints: np.ndarray, 
                                       normal_base: np.ndarray,
                                       panel_center_base: np.ndarray,
                                       distance: float = 0.30) -> Optional[np.ndarray]:
    """
    è®¡ç®—å¯¹é½æ³•å‘é‡çš„æœ«ç«¯ä½å§¿ï¼Œä¿æŒæŒ‡å®šè·ç¦»
    
    ç­–ç•¥ï¼šä¼˜å…ˆä¿æŒå½“å‰ä½ç½®ï¼Œåªè°ƒæ•´å§¿æ€å¯¹é½æ³•å‘é‡
    
    å‚æ•°:
        current_joints: å½“å‰å…³èŠ‚è§’åº¦
        normal_base: é¢æ¿æ³•å‘é‡ï¼ˆåŸºåº§ç³»ï¼ŒæŒ‡å‘å¤–ä¾§ï¼‰
        panel_center_base: é¢æ¿ä¸­å¿ƒç‚¹ï¼ˆåŸºåº§ç³»ï¼‰
        distance: ä¸é¢æ¿çš„è·ç¦»ï¼ˆç±³ï¼Œé»˜è®¤30cmï¼‰
    
    è¿”å›:
        ç›®æ ‡å…³èŠ‚è§’åº¦ æˆ– None
    """
    # è·å–å½“å‰æœ«ç«¯ä½ç½®
    current_T = piper_arm.forward_kinematics(current_joints)
    current_position = current_T[:3, 3]
    
    # ç­–ç•¥1ï¼šåªè°ƒæ•´å§¿æ€ï¼Œä¿æŒå½“å‰ä½ç½®ï¼ˆé¿å…å¤§å¹…ç§»åŠ¨å¯¼è‡´è¶…é™ï¼‰
    target_position = current_position
    
    # æ„é€ ç›®æ ‡æ—‹è½¬çŸ©é˜µï¼šZè½´å¯¹é½æ³•å‘é‡ï¼ˆæŒ‡å‘é¢æ¿ï¼‰
    z_axis = normal_base / np.linalg.norm(normal_base)
    
    # é€‰æ‹©ä¸€ä¸ª"ä¸Š"æ–¹å‘
    world_up = np.array([0, 0, 1])
    if abs(np.dot(z_axis, world_up)) > 0.95:
        world_up = np.array([1, 0, 0])
    
    x_axis = np.cross(world_up, z_axis)
    x_axis = x_axis / np.linalg.norm(x_axis)
    
    y_axis = np.cross(z_axis, x_axis)
    
    # ç›®æ ‡å˜æ¢çŸ©é˜µ
    target_T = np.eye(4)
    target_T[:3, 0] = x_axis
    target_T[:3, 1] = y_axis
    target_T[:3, 2] = z_axis
    target_T[:3, 3] = target_position
    
    # IKæ±‚è§£ï¼ˆä½¿ç”¨refinedç‰ˆæœ¬ï¼Œæ›´ç¨³å®šï¼‰
    try:
        target_joints = piper_arm.inverse_kinematics_refined(target_T, initial_guess=current_joints)
        if target_joints is None:
            return None
        return target_joints
    except Exception as e:
        # å¦‚æœrefinedå¤±è´¥ï¼Œå°è¯•åŸºç¡€ç‰ˆæœ¬
        try:
            target_joints = piper_arm.inverse_kinematics(target_T)
            if target_joints is None:
                return None
            return target_joints
        except:
            return None


def compute_aligned_pose(current_joints: np.ndarray, 
                        normal_base: np.ndarray,
                        offset_distance: float = 0.0) -> Optional[np.ndarray]:
    """
    è®¡ç®—å¯¹é½æ³•å‘é‡çš„æœ«ç«¯ä½å§¿ï¼ˆæ—§ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
    
    å‚æ•°:
        current_joints: å½“å‰å…³èŠ‚è§’åº¦
        normal_base: é¢æ¿æ³•å‘é‡ï¼ˆåŸºåº§ç³»ï¼‰
        offset_distance: åç§»è·ç¦»ï¼ˆç±³ï¼Œæ­£å€¼è¿œç¦»é¢æ¿ï¼‰
    
    è¿”å›:
        ç›®æ ‡å…³èŠ‚è§’åº¦ æˆ– None
    """
    # è·å–å½“å‰æœ«ç«¯ä½ç½®
    current_T = piper_arm.forward_kinematics(current_joints)
    current_position = current_T[:3, 3]
    
    # è®¡ç®—ç›®æ ‡ä½ç½®ï¼ˆåŠ ä¸Šåç§»ï¼‰
    target_position = current_position + normal_base * offset_distance
    
    # æ„é€ ç›®æ ‡æ—‹è½¬çŸ©é˜µï¼šZè½´å¯¹é½æ³•å‘é‡
    z_axis = normal_base / np.linalg.norm(normal_base)
    
    # é€‰æ‹©ä¸€ä¸ª"ä¸Š"æ–¹å‘
    world_up = np.array([0, 0, 1])
    if abs(np.dot(z_axis, world_up)) > 0.95:
        world_up = np.array([1, 0, 0])
    
    x_axis = np.cross(world_up, z_axis)
    x_axis = x_axis / np.linalg.norm(x_axis)
    
    y_axis = np.cross(z_axis, x_axis)
    
    # ç›®æ ‡å˜æ¢çŸ©é˜µ
    target_T = np.eye(4)
    target_T[:3, 0] = x_axis
    target_T[:3, 1] = y_axis
    target_T[:3, 2] = z_axis
    target_T[:3, 3] = target_position
    
    # IKæ±‚è§£ï¼ˆä½¿ç”¨refinedç‰ˆæœ¬ï¼Œæ›´ç¨³å®šï¼‰
    try:
        target_joints = piper_arm.inverse_kinematics_refined(target_T, initial_guess=current_joints)
        if target_joints is None:
            return None
        return target_joints
    except Exception as e:
        # å¦‚æœrefinedå¤±è´¥ï¼Œå°è¯•åŸºç¡€ç‰ˆæœ¬
        try:
            target_joints = piper_arm.inverse_kinematics(target_T)
            if target_joints is None:
                return None
            return target_joints
        except:
            return None


def move_to_joints_moveit(target_joints: np.ndarray) -> bool:
    """
    ä½¿ç”¨MoveIt2ç§»åŠ¨åˆ°ç›®æ ‡å…³èŠ‚è§’åº¦
    
    å‚æ•°:
        target_joints: ç›®æ ‡å…³èŠ‚è§’åº¦ï¼ˆå¼§åº¦ï¼‰
    
    è¿”å›:
        True: æˆåŠŸ, False: å¤±è´¥
    """
    global action_client, joint_state_publisher, ros_node
    
    if action_client is None:
        print("  âš ï¸  MoveIt2 action clientæœªåˆå§‹åŒ–")
        return False
    
    # æ£€æŸ¥å…³èŠ‚é™ä½
    joint_limits_rad = [
        (-PI, PI),          # J1: Â±180Â°
        (0, PI),            # J2: 0~180Â°
        (-PI, 0),           # J3: -180~0Â°
        (-PI, PI),          # J4: Â±180Â°
        (-70*PI/180, 70*PI/180),  # J5: Â±70Â°
        (-PI, PI)           # J6: Â±180Â°
    ]
    
    for i, (joint_val, (min_val, max_val)) in enumerate(zip(target_joints, joint_limits_rad)):
        if joint_val < min_val or joint_val > max_val:
            print(f"  âš ï¸  å…³èŠ‚{i+1}è¶…é™: {joint_val*180/PI:.1f}Â° (èŒƒå›´: {min_val*180/PI:.1f}~{max_val*180/PI:.1f}Â°)")
            return False
    
    # åˆ›å»ºMoveGroup.action goalæ¶ˆæ¯
    goal_msg = MoveGroupAction.Goal()
    goal_msg.request = MotionPlanRequest()
    goal_msg.request.group_name = 'piper'
    goal_msg.request.num_planning_attempts = 5
    goal_msg.request.allowed_planning_time = 2.0
    goal_msg.request.max_velocity_scaling_factor = 0.5
    goal_msg.request.max_acceleration_scaling_factor = 0.5
    
    # è®¾ç½®å…³èŠ‚çº¦æŸ
    goal_msg.request.goal_constraints.append(Constraints())
    joint_names = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']
    
    for i, (name, position) in enumerate(zip(joint_names, target_joints)):
        constraint = JointConstraint()
        constraint.joint_name = name
        constraint.position = float(position)
        constraint.tolerance_above = 0.01
        constraint.tolerance_below = 0.01
        constraint.weight = 1.0
        goal_msg.request.goal_constraints[0].joint_constraints.append(constraint)
    
    # å‘é€ç›®æ ‡ï¼ˆéé˜»å¡ï¼‰
    try:
        action_client.send_goal_async(goal_msg)
        
        # åŒæ—¶å‘å¸ƒjoint_statesä¾›å…¶ä»–èŠ‚ç‚¹ä½¿ç”¨
        if joint_state_publisher:
            js_msg = JointState()
            js_msg.header.stamp = ros_node.get_clock().now().to_msg()
            js_msg.name = joint_names
            js_msg.position = target_joints.tolist()
            joint_state_publisher.publish(js_msg)
        
        return True
    except Exception as e:
        print(f"  âš ï¸  MoveIt2å‘é€ç›®æ ‡å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å¾ªç¯ï¼šå®æ—¶è¿½è¸ªé¢æ¿æ³•å‘é‡"""
    print("\n" + "="*70)
    print("å®æ—¶è¿½è¸ªé¢æ¿æ³•å‘é‡ (ä¼˜åŒ–ç‰ˆ)")
    print("="*70)
    print("åŠŸèƒ½ï¼šå¤¹çˆªZè½´å§‹ç»ˆå‚ç›´å¯¹é½äºé¢æ¿")
    print("æ“ä½œï¼š")
    print("  - ç§»åŠ¨ç›¸æœºå¯¹å‡†é¢æ¿")
    print("  - æŒ‰ 'q' é€€å‡º")
    print("  - æŒ‰ 's' æš‚åœ/ç»§ç»­è¿½è¸ª")
    print("  - æŒ‰ 'd' åˆ‡æ¢æ˜¾ç¤ºæ¨¡å¼ï¼ˆæé€Ÿï¼‰")
    print("="*70 + "\n")
    
    # åˆå§‹åŒ–ç¡¬ä»¶
    if not initialize_hardware():
        print("ç¡¬ä»¶åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º")
        return
    
    # åˆå§‹åŒ–ROS2å’ŒMoveIt2
    if not initialize_ros2():
        print("ROS2åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡º")
        return
    
    # åˆ›å»ºæ·±åº¦å¯¹é½å¯¹è±¡
    align = rs.align(rs.stream.color)
    
    # çŠ¶æ€å˜é‡
    tracking_enabled = True
    display_enabled = True  # æ˜¾ç¤ºå¼€å…³
    frame_count = 0
    last_update_time = time.time()
    
    print("\nå¼€å§‹è¿½è¸ª...\n")
    print("ğŸ’¡ æç¤º: æŒ‰ 'd' å…³é—­æ˜¾ç¤ºå¯ä»¥æé«˜è¿½è¸ªé€Ÿåº¦åˆ° 15Hz+\n")
    
    try:
        while True:
            frame_count += 1
            
            # è·å–å¯¹é½çš„å¸§
            frames = pipeline.wait_for_frames()
            aligned_frames = align.process(frames)
            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()
            
            if not depth_frame or not color_frame:
                continue
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆä»…åœ¨æ˜¾ç¤ºæ—¶ï¼‰
            if display_enabled:
                color_image = np.asanyarray(color_frame.get_data())
                
                # åœ¨å›¾åƒä¸­å¿ƒç”»åå­—
                center_x, center_y = 320, 240
                cv2.line(color_image, (center_x - 30, center_y), (center_x + 30, center_y), (0, 255, 0), 2)
                cv2.line(color_image, (center_x, center_y - 30), (center_x, center_y + 30), (0, 255, 0), 2)
                cv2.circle(color_image, (center_x, center_y), 60, (255, 0, 0), 2)
            else:
                color_image = None
                center_x, center_y = 320, 240
            
            # æ¯2å¸§æ›´æ–°ä¸€æ¬¡ï¼ˆæé«˜å“åº”é€Ÿåº¦ï¼‰
            if tracking_enabled and frame_count % 2 == 0:
                # æ£€æµ‹æ³•å‘é‡å’Œé¢æ¿ä¸­å¿ƒç‚¹
                detection_result = detect_panel_normal(depth_frame, color_frame, center_x, center_y)
                
                if detection_result is not None:
                    normal_camera, panel_center_camera = detection_result
                    
                    # è¯»å–å½“å‰å…³èŠ‚è§’åº¦
                    current_joints = get_current_joints()
                    
                    # è½¬æ¢æ³•å‘é‡åˆ°åŸºåº§æ ‡ç³»
                    normal_base = transform_normal_to_base(normal_camera, current_joints)
                    
                    # è½¬æ¢é¢æ¿ä¸­å¿ƒç‚¹åˆ°åŸºåº§æ ‡ç³»
                    base_T_link6 = piper_arm.forward_kinematics(current_joints)
                    link6_T_cam = np.eye(4)
                    link6_T_cam[:3, :3] = quaternion_to_rotation_matrix(piper_arm.link6_q_camera)
                    link6_T_cam[:3, 3] = piper_arm.link6_t_camera
                    base_T_cam = base_T_link6 @ link6_T_cam
                    
                    panel_center_camera_h = np.array([panel_center_camera[0], panel_center_camera[1], panel_center_camera[2], 1.0])
                    panel_center_base = base_T_cam @ panel_center_camera_h
                    panel_center_base = panel_center_base[:3]
                    
                    # ğŸ”§ ç®€åŒ–ç­–ç•¥ï¼šåªè°ƒæ•´å§¿æ€å¯¹é½æ³•å‘é‡ï¼Œä¸æ”¹å˜ä½ç½®
                    # è¿™æ ·å¯ä»¥é¿å…IKæ±‚è§£è¶…é™é—®é¢˜
                    target_joints = compute_aligned_pose(
                        current_joints, normal_base, offset_distance=0.0
                    )
                    
                    if target_joints is not None:
                        # ä½¿ç”¨MoveIt2ç§»åŠ¨æœºæ¢°è‡‚
                        success = move_to_joints_moveit(target_joints)
                        if not success:
                            # å¦‚æœè¶…é™ï¼Œæ‰“å°å½“å‰å…³èŠ‚è§’åº¦
                            print(f"  å½“å‰å…³èŠ‚è§’(åº¦): {np.array(current_joints)*180/PI}")
                            continue
                        
                        # æ˜¾ç¤ºä¿¡æ¯
                        now = time.time()
                        dt = now - last_update_time
                        last_update_time = now
                        
                        # è®¡ç®—å½“å‰æœ«ç«¯ä½ç½®ä¸é¢æ¿ä¸­å¿ƒçš„è·ç¦»
                        current_T_check = piper_arm.forward_kinematics(get_current_joints())
                        current_pos = current_T_check[:3, 3]
                        actual_distance = np.linalg.norm(current_pos - panel_center_base)
                        
                        # è®¡ç®—å§¿æ€å¯¹é½ç¨‹åº¦ï¼ˆZè½´ä¸æ³•å‘é‡çš„å¤¹è§’ï¼‰
                        current_z_axis = current_T_check[:3, 2]
                        alignment_angle = np.arccos(np.clip(np.dot(current_z_axis, normal_base), -1, 1)) * 180 / PI
                        
                        print(f"[è¿½è¸ª] æ³•å‘é‡: ({normal_base[0]:+.3f}, {normal_base[1]:+.3f}, {normal_base[2]:+.3f}) | "
                              f"è·ç¦»: {actual_distance*100:.1f}cm | å¯¹é½è§’åº¦: {alignment_angle:.1f}Â° | æ›´æ–°: {dt:.2f}s")
                        
                        # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºçŠ¶æ€
                        if display_enabled:
                            cv2.putText(color_image, "Tracking: ON", (10, 30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                            cv2.putText(color_image, f"Normal: ({normal_base[0]:.2f}, {normal_base[1]:.2f}, {normal_base[2]:.2f})", 
                                       (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                            cv2.putText(color_image, f"Distance: {actual_distance*100:.1f}cm (target: 30cm)", 
                                       (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    else:
                        if display_enabled:
                            cv2.putText(color_image, "IK Failed", (10, 30), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                else:
                    if display_enabled:
                        cv2.putText(color_image, "No Panel Detected", (10, 30), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            else:
                if display_enabled:
                    cv2.putText(color_image, "Tracking: OFF (Press 's')", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # æ˜¾ç¤ºå›¾åƒï¼ˆä»…åœ¨æ˜¾ç¤ºæ¨¡å¼ä¸‹ï¼‰
            if display_enabled and color_image is not None:
                cv2.imshow('Panel Normal Tracking', color_image)
            
            # é”®ç›˜æ§åˆ¶
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\né€€å‡ºè¿½è¸ª...")
                break
            elif key == ord('s'):
                tracking_enabled = not tracking_enabled
                status = "ON" if tracking_enabled else "OFF"
                print(f"\nè¿½è¸ªçŠ¶æ€: {status}")
            elif key == ord('d'):
                display_enabled = not display_enabled
                status = "ON" if display_enabled else "OFF (æé€Ÿæ¨¡å¼)"
                print(f"\næ˜¾ç¤ºçŠ¶æ€: {status}")
                if not display_enabled:
                    cv2.destroyAllWindows()
    
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ä¸­æ–­")
    
    finally:
        # æ¸…ç†èµ„æº
        if pipeline:
            pipeline.stop()
        cv2.destroyAllWindows()
        
        # å…³é—­ROS2
        if ros2_executor:
            ros2_executor.shutdown()
        if ros_node:
            ros_node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()
        
        print("\nç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()
